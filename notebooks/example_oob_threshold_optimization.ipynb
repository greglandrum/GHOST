{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function to optimize the decision threshold using the out-of-bag (oob) prediction probabilities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_it_oob_optimization(oob_probs, labels_train, thresholds, ThOpt_metrics = 'Kappa'):\n",
    "    \"\"\"Optimize the decision threshold based on the prediction probabilities of the out-of-bag set of random forest.\n",
    "    The threshold that maximizes the Cohen's kappa coefficient or a ROC-based criterion \n",
    "    on the out-of-bag set is chosen as optimal.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    oob_probs : list of floats\n",
    "        Positive prediction probabilities for the out-of-bag set of a trained random forest model\n",
    "    labels_train: list of int\n",
    "        True labels for the training set\n",
    "    thresholds: list of floats\n",
    "        List of decision thresholds to screen for classification\n",
    "    ThOpt_metrics: str\n",
    "        Optimization metric. Choose between \"Kappa\" and \"ROC\"\n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    thresh: float\n",
    "        Optimal decision threshold for classification\n",
    "    \"\"\"\n",
    "    # Optmize the decision threshold based on the Cohen's Kappa coefficient\n",
    "    if ThOpt_metrics == 'Kappa':\n",
    "        tscores = []\n",
    "        # evaluate the score on the oob using different thresholds\n",
    "        for thresh in thresholds:\n",
    "            scores = [1 if x>=thresh else 0 for x in oob_probs]\n",
    "            kappa = metrics.cohen_kappa_score(labels_train,scores)\n",
    "            tscores.append((np.round(kappa,3),thresh))\n",
    "        # select the threshold providing the highest kappa score as optimal\n",
    "        tscores.sort(reverse=True)\n",
    "        thresh = tscores[0][-1]\n",
    "    # Optmize the decision threshold based on the ROC-curve\n",
    "    elif ThOpt_metrics == 'ROC':\n",
    "        # ROC optimization with thresholds determined by the roc_curve function of sklearn\n",
    "        fpr, tpr, thresholds_roc = metrics.roc_curve(labels_train, oob_probs, pos_label=1)\n",
    "        specificity = 1-fpr\n",
    "        roc_dist_01corner = (2*tpr*specificity)/(tpr+specificity)\n",
    "        thresh = thresholds_roc[np.argmax(roc_dist_01corner)]\n",
    "    return thresh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function to calculate classification metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "def calc_metrics(labels_test, test_probs, threshold = 0.5):\n",
    "    scores = [1 if x>=threshold else 0 for x in test_probs]\n",
    "    auc = metrics.roc_auc_score(labels_test, test_probs)\n",
    "    kappa = metrics.cohen_kappa_score(labels_test,scores)\n",
    "    confusion = metrics.confusion_matrix(labels_test,scores, labels=list(set(labels_test)))\n",
    "    print('thresh: %.2f, kappa: %.3f, AUC test-set: %.3f'%(threshold, kappa, auc))\n",
    "    print(confusion)\n",
    "    print(metrics.classification_report(labels_test,scores))\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh: 0.50, kappa: 0.202, AUC test-set: 0.829\n",
      "[[158   1]\n",
      " [ 35   6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.99      0.90       159\n",
      "           1       0.86      0.15      0.25        41\n",
      "\n",
      "    accuracy                           0.82       200\n",
      "   macro avg       0.84      0.57      0.57       200\n",
      "weighted avg       0.83      0.82      0.76       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generate a binary imbalanced classification problem, with 80% zeros and 20% ones.\n",
    "X, y = make_classification(n_samples=1000, n_features=20,\n",
    "                           n_informative=14, n_redundant=0,\n",
    "                           random_state=0, shuffle=False, weights = [0.8, 0.2])\n",
    "\n",
    "# Train - test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y, random_state=0)\n",
    "\n",
    "# Train a RF classifier\n",
    "cls = RandomForestClassifier(max_depth=6, oob_score=True)\n",
    "cls.fit(X_train, y_train)\n",
    "\n",
    "# Get prediction probabilities for the test set\n",
    "test_probs = cls.predict_proba(X_test)[:,1] \n",
    "\n",
    "# Print confusion matrix and classification metrics\n",
    "calc_metrics(y_test, test_probs, threshold = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optimize the decision threshold:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the Cohen's Kappa as optimization metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh: 0.30, kappa: 0.559, AUC test-set: 0.829\n",
      "[[144  15]\n",
      " [ 14  27]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91       159\n",
      "           1       0.64      0.66      0.65        41\n",
      "\n",
      "    accuracy                           0.85       200\n",
      "   macro avg       0.78      0.78      0.78       200\n",
      "weighted avg       0.86      0.85      0.86       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# extract oob prediction probabilities from the trained RF model\n",
    "oob_probs = cls.oob_decision_function_\n",
    "oob_probs = [x[1] for x in oob_probs]\n",
    "\n",
    "# optmize the threshold \n",
    "thresholds = np.round(np.arange(0.05,0.55,0.05),2)\n",
    "threshold1 = run_it_oob_optimization(oob_probs, y_train, thresholds, ThOpt_metrics = 'Kappa') \n",
    "\n",
    "# Print confusion matrix and classification metrics\n",
    "calc_metrics(y_test, test_probs, threshold = threshold1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
