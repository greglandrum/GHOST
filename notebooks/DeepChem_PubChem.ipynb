{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "virtual-trustee",
   "metadata": {},
   "source": [
    "## Multi-Task Classification Model for the PubChem datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floppy-peninsula",
   "metadata": {},
   "source": [
    "To execute this notebook, first install the DeepChem library:\n",
    "\n",
    "    conda create --name deepchem-test\n",
    "    conda activate deepchem-test\n",
    "    conda install -y -c conda-forge rdkit nb_conda_kernels matplotlib\n",
    "    pip3 install tensorflow==2.2.0\n",
    "    pip3 install --pre deepchem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "digital-multiple",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import rdFingerprintGenerator\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import SimDivFilters\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gzip\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import deepchem as dc\n",
    "from rdkit.Chem.MolStandardize import rdMolStandardize\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "north-amsterdam",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import random\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import resample\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "beautiful-corner",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import RDLogger\n",
    "lg = RDLogger.logger()\n",
    "lg.setLevel(RDLogger.CRITICAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twelve-roommate",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "clean-finance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove counterions: Take the largest organic fragment\n",
    "def salt_remover(smiles):\n",
    "    rmv = rdMolStandardize.LargestFragmentChooser()\n",
    "    cleaned_smiles = []\n",
    "    for smi in smiles:\n",
    "        if \".\" in smi:\n",
    "            cleaned_smiles.append(Chem.MolToSmiles(rmv.choose(Chem.MolFromSmiles(smi))))\n",
    "        else:\n",
    "            cleaned_smiles.append(smi)\n",
    "    return cleaned_smiles\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aggressive-glory",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "\n",
    "def optimize_threshold_from_predictions(labels, probs, thresholds, \n",
    "                                    ThOpt_metrics = 'Kappa', N_subsets = 100, \n",
    "                                    subsets_size = 0.2, with_replacement = False, random_seed = None):\n",
    "\n",
    "    \"\"\" Optimize the decision threshold based on subsets of the training set.\n",
    "    The threshold that maximizes the Cohen's kappa coefficient or a ROC-based criterion \n",
    "    on the training subsets is chosen as optimal.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    labels: sequence of ints\n",
    "        True labels for the training set\n",
    "    probs: sequence of floats\n",
    "        predicted probabilities for minority class from the training set \n",
    "        (e.g. output from cls.predict_proba(data)[:,1])\n",
    "    thresholds: list of floats\n",
    "        List of decision thresholds to screen for classification\n",
    "    ThOpt_metrics: str\n",
    "        Optimization metric. Choose between \"Kappa\" and \"ROC\"\n",
    "    N_subsets: int\n",
    "        Number of training subsets to use in the optimization\n",
    "    subsets_size: float or int\n",
    "        Size of the subsets. if float, represents the proportion of the dataset to include in the subsets. \n",
    "        If integer, it represents the actual number of instances to include in the subsets. \n",
    "    with_replacement: bool\n",
    "        The subsets are drawn randomly. True to draw the subsets with replacement\n",
    "    random_seed: int    \n",
    "        random number to seed the drawing of the subsets\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    thresh: float\n",
    "        Optimal decision threshold for classification\n",
    "    \"\"\"\n",
    "    # seeding\n",
    "    np.random.seed(random_seed)\n",
    "    random_seeds = np.random.randint(N_subsets*10, size=N_subsets)  \n",
    "    \n",
    "    df_preds = pd.DataFrame({'labels':labels,'probs':probs})\n",
    "    thresh_names = [str(x) for x in thresholds]\n",
    "    for thresh in thresholds:\n",
    "        df_preds[str(thresh)] = [1 if x>=thresh else 0 for x in probs]\n",
    "    # Optmize the decision threshold based on the Cohen's Kappa coefficient\n",
    "    if ThOpt_metrics == 'Kappa':\n",
    "        # pick N_subsets training subsets and determine the threshold that provides the highest kappa on each \n",
    "        # of the subsets\n",
    "        kappa_accum = []\n",
    "        for i in range(N_subsets):\n",
    "            if with_replacement:\n",
    "                if isinstance(subsets_size, float):\n",
    "                    Nsamples = int(df_preds.shape[0]*subsets_size)\n",
    "                elif isinstance(subsets_size, int):\n",
    "                    Nsamples = subsets_size                    \n",
    "                df_subset = resample(df_preds, replace=True, n_samples = Nsamples, stratify=labels, random_state = random_seeds[i])\n",
    "                labels_subset = df_subset['labels']\n",
    "            else:\n",
    "                df_tmp, df_subset, labels_tmp, labels_subset = train_test_split(df_preds, labels, test_size = subsets_size, stratify = labels, random_state = random_seeds[i])\n",
    "            kappa_train_subset = []\n",
    "            for col1 in thresh_names:\n",
    "                kappa_train_subset.append(metrics.cohen_kappa_score(labels_subset, list(df_subset[col1])))\n",
    "            kappa_accum.append(kappa_train_subset)\n",
    "        # determine the threshold that provides the best results on the training subsets\n",
    "        y_values_median, y_values_std = helper_calc_median_std(kappa_accum)\n",
    "        opt_thresh = thresholds[np.argmax(y_values_median)]\n",
    "    # Optmize the decision threshold based on the ROC-curve, as described here https://doi.org/10.1007/s11548-013-0913-8\n",
    "    elif ThOpt_metrics == 'ROC':\n",
    "        sensitivity_accum = []\n",
    "        specificity_accum = []\n",
    "        # Calculate sensitivity and specificity for a range of thresholds and N_subsets\n",
    "        for i in range(N_subsets):\n",
    "            if with_replacement:\n",
    "                if isinstance(subsets_size, float):\n",
    "                    Nsamples = int(df_preds.shape[0]*subsets_size)\n",
    "                elif isinstance(subsets_size, int):\n",
    "                    Nsamples = subsets_size                    \n",
    "                df_subset = resample(df_preds, n_samples = Nsamples, stratify=labels, random_state = random_seeds[i])\n",
    "                labels_subset = list(df_subset['labels'])\n",
    "            else:\n",
    "                df_tmp, df_subset, labels_tmp, labels_subset = train_test_split(df_preds, labels, test_size = subsets_size, stratify = labels, random_state = random_seeds[i])\n",
    "            sensitivity = []\n",
    "            specificity = []\n",
    "            for thresh in thresholds:\n",
    "                scores = [1 if x >= thresh else 0 for x in df_subset['probs']]\n",
    "                tn, fp, fn, tp = metrics.confusion_matrix(labels_subset, scores, labels=sorted(set(labels))).ravel()\n",
    "                sensitivity.append(tp/(tp+fn))\n",
    "                specificity.append(tn/(tn+fp))\n",
    "            sensitivity_accum.append(sensitivity)\n",
    "            specificity_accum.append(specificity)\n",
    "        # determine the threshold that provides the best results on the training subsets\n",
    "        median_sensitivity, std_sensitivity = helper_calc_median_std(sensitivity_accum)\n",
    "        median_specificity, std_specificity = helper_calc_median_std(specificity_accum)\n",
    "        roc_dist_01corner = (2*median_sensitivity*median_specificity)/(median_sensitivity+median_specificity)\n",
    "        opt_thresh = thresholds[np.argmax(roc_dist_01corner)]\n",
    "    return opt_thresh\n",
    "\n",
    "def helper_calc_median_std(specificity):\n",
    "    # Calculate median and std of the columns of a pandas dataframe\n",
    "    arr = np.array(specificity)\n",
    "    y_values_median = np.median(arr,axis=0)\n",
    "    y_values_std = np.std(arr,axis=0)\n",
    "    return y_values_median, y_values_std "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quality-trance",
   "metadata": {},
   "source": [
    "## Prepare PubChem assays datasets for DeepChem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "commercial-funeral",
   "metadata": {},
   "source": [
    "Read in PubChem assays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "global-finish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>canonical_smiles</th>\n",
       "      <th>compound_chembl_id</th>\n",
       "      <th>assay_chembl_id</th>\n",
       "      <th>standard_relation</th>\n",
       "      <th>Mean(standard_value)</th>\n",
       "      <th>activity_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Br.Br.C(c1ccncc1)c2cnc[nH]2</td>\n",
       "      <td>CHEMBL1316355</td>\n",
       "      <td>CHEMBL1614421</td>\n",
       "      <td>=</td>\n",
       "      <td>44668.4</td>\n",
       "      <td>Inconclusive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Br.Br.NCCSC(=N)N</td>\n",
       "      <td>CHEMBL1256182</td>\n",
       "      <td>CHEMBL1614249</td>\n",
       "      <td>=</td>\n",
       "      <td>31622.8</td>\n",
       "      <td>Not Active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Br.Br.NCCSC(=N)N</td>\n",
       "      <td>CHEMBL1256182</td>\n",
       "      <td>CHEMBL1614364</td>\n",
       "      <td>=</td>\n",
       "      <td>446.7</td>\n",
       "      <td>Not Active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Br.Br.NCCSC(=N)N</td>\n",
       "      <td>CHEMBL1256182</td>\n",
       "      <td>CHEMBL1614421</td>\n",
       "      <td>=</td>\n",
       "      <td>17782.8</td>\n",
       "      <td>Inconclusive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Br.Br.NCCSC(=N)N</td>\n",
       "      <td>CHEMBL1256182</td>\n",
       "      <td>CHEMBL1794375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35481.3</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              canonical_smiles compound_chembl_id assay_chembl_id  \\\n",
       "0  Br.Br.C(c1ccncc1)c2cnc[nH]2      CHEMBL1316355   CHEMBL1614421   \n",
       "1             Br.Br.NCCSC(=N)N      CHEMBL1256182   CHEMBL1614249   \n",
       "2             Br.Br.NCCSC(=N)N      CHEMBL1256182   CHEMBL1614364   \n",
       "3             Br.Br.NCCSC(=N)N      CHEMBL1256182   CHEMBL1614421   \n",
       "4             Br.Br.NCCSC(=N)N      CHEMBL1256182   CHEMBL1794375   \n",
       "\n",
       "  standard_relation  Mean(standard_value) activity_comment  \n",
       "0                 =               44668.4     Inconclusive  \n",
       "1                 =               31622.8       Not Active  \n",
       "2                 =                 446.7       Not Active  \n",
       "3                 =               17782.8     Inconclusive  \n",
       "4               NaN               35481.3           active  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gzip.open('data/ChEMBL_PubChem_HTS.csv.gz') as inf:\n",
    "    pubchem_d = pd.read_csv(inf)\n",
    "pubchem_d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "upper-excess",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/pubchem_data.pkl','rb') as inf:\n",
    "    pubchem_d,pubchem_assay_lookup = pickle.load(inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consistent-bottle",
   "metadata": {},
   "source": [
    "Prepare dataframe with data from all 8 PubChem datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aboriginal-synthetic",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['canonical_smiles', 'compound_chembl_id', 'assay_chembl_id']\n",
    "df_pubchem_assays = pd.DataFrame()\n",
    "for i, assay_id in enumerate(pubchem_assay_lookup):\n",
    "    assay = pubchem_d.loc[pubchem_d['assay_chembl_id']==assay_id]\n",
    "    acts = pd.concat((assay.loc[assay['activity_comment'] == 'Active'], \n",
    "                      assay.loc[assay['activity_comment'] == 'active']))\n",
    "    inacts = pd.concat((assay.loc[assay['activity_comment'] == 'inactive'],\n",
    "                        assay.loc[assay['activity_comment'] == 'inconclusive'], \n",
    "                        assay.loc[assay['activity_comment'] == 'Inconclusive'], \n",
    "                        assay.loc[assay['activity_comment'] == 'Not Active']))\n",
    "    acts['canonical_smiles'] = salt_remover(acts['canonical_smiles'])\n",
    "    inacts['canonical_smiles'] = salt_remover(inacts['canonical_smiles'])\n",
    "    acts = acts[columns]\n",
    "    inacts = inacts[columns]\n",
    "    acts[f'label_{assay_id}'] = 1\n",
    "    inacts[f'label_{assay_id}'] = 0\n",
    "    # retrieve compound IDs\n",
    "    mol_names = list(acts['compound_chembl_id']) + list(inacts['compound_chembl_id'])\n",
    "    if i==0:\n",
    "        df_pubchem_assays = pd.concat((acts, inacts))\n",
    "    else:\n",
    "        df = pd.concat((acts, inacts))\n",
    "        df_pubchem_assays = pd.concat((df_pubchem_assays, df), axis=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-patrol",
   "metadata": {},
   "source": [
    "**Labelling for Multitask Classification:**\n",
    "\n",
    "For the majority of compounds, data are available only for one task. \n",
    "For the other tasks where no data is available, compounds are labelled as inactive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "exclusive-integration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deal with duplicate compounds\n",
    "for i, c1 in enumerate(list(df_pubchem_assays[df_pubchem_assays.compound_chembl_id.duplicated()]['compound_chembl_id'])):\n",
    "    tmp = df_pubchem_assays.loc[df_pubchem_assays.compound_chembl_id == c1].fillna(method='ffill').fillna(method='bfill')\n",
    "    if i==0:\n",
    "        df_no_duplicates = tmp.fillna(0).drop(columns='assay_chembl_id').drop_duplicates(keep='first') \n",
    "    else:\n",
    "        df_no_duplicates = pd.concat((df_no_duplicates, tmp.fillna(0).drop(columns='assay_chembl_id').drop_duplicates(keep='first') ))\n",
    "\n",
    "\n",
    "df_no_duplicates.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "liquid-italic",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmpds_duplicates = list(df_no_duplicates.compound_chembl_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "focal-apartment",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carmenesposito/Desktop/Softwares/miniconda3/envs/deepchem-test/lib/python3.7/site-packages/pandas/core/frame.py:4315: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "df_no_duplicates_part1 = df_pubchem_assays.loc[~df_pubchem_assays.compound_chembl_id.isin(cmpds_duplicates)]\n",
    "df_no_duplicates_part1.drop(columns='assay_chembl_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "practical-contemporary",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.concat((df_no_duplicates, df_no_duplicates_part1.fillna(0)))\n",
    "df_new.reset_index(inplace=True, drop=True)\n",
    "df_pubchem_assays_new = df_new.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "proprietary-cyprus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>canonical_smiles</th>\n",
       "      <th>compound_chembl_id</th>\n",
       "      <th>label_CHEMBL1794375</th>\n",
       "      <th>label_CHEMBL1614421</th>\n",
       "      <th>label_CHEMBL1614249</th>\n",
       "      <th>label_CHEMBL1614166</th>\n",
       "      <th>label_CHEMBL1614364</th>\n",
       "      <th>label_CHEMBL1613933</th>\n",
       "      <th>label_CHEMBL3214913</th>\n",
       "      <th>label_CHEMBL3215169</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c1cc2c(cc1-c1csc(NNC3=NCCCCC3)n1)OCCO2</td>\n",
       "      <td>CHEMBL1532195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c1ccc(-c2csc(NNC3=NCCCCC3)n2)cc1</td>\n",
       "      <td>CHEMBL1510704</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c1ccc(-c2csc(Nc3ccc4c(c3)OCCO4)n2)cc1</td>\n",
       "      <td>CHEMBL1410042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CC(=O)NNc1nc(-c2ccccc2)cs1</td>\n",
       "      <td>CHEMBL1453036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CC(=O)Nc1nc(C)c(-c2csc(Nc3ccc(O)cc3)n2)s1</td>\n",
       "      <td>CHEMBL1455993</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            canonical_smiles compound_chembl_id  \\\n",
       "0     c1cc2c(cc1-c1csc(NNC3=NCCCCC3)n1)OCCO2      CHEMBL1532195   \n",
       "1           c1ccc(-c2csc(NNC3=NCCCCC3)n2)cc1      CHEMBL1510704   \n",
       "2      c1ccc(-c2csc(Nc3ccc4c(c3)OCCO4)n2)cc1      CHEMBL1410042   \n",
       "3                 CC(=O)NNc1nc(-c2ccccc2)cs1      CHEMBL1453036   \n",
       "4  CC(=O)Nc1nc(C)c(-c2csc(Nc3ccc(O)cc3)n2)s1      CHEMBL1455993   \n",
       "\n",
       "   label_CHEMBL1794375  label_CHEMBL1614421  label_CHEMBL1614249  \\\n",
       "0                  0.0                  1.0                  0.0   \n",
       "1                  0.0                  1.0                  0.0   \n",
       "2                  0.0                  1.0                  0.0   \n",
       "3                  0.0                  1.0                  0.0   \n",
       "4                  1.0                  1.0                  0.0   \n",
       "\n",
       "   label_CHEMBL1614166  label_CHEMBL1614364  label_CHEMBL1613933  \\\n",
       "0                  0.0                  0.0                  0.0   \n",
       "1                  0.0                  0.0                  0.0   \n",
       "2                  0.0                  0.0                  0.0   \n",
       "3                  0.0                  0.0                  0.0   \n",
       "4                  0.0                  0.0                  0.0   \n",
       "\n",
       "   label_CHEMBL3214913  label_CHEMBL3215169  \n",
       "0                  0.0                  0.0  \n",
       "1                  0.0                  0.0  \n",
       "2                  0.0                  0.0  \n",
       "3                  0.0                  0.0  \n",
       "4                  0.0                  0.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pubchem_assays_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-integer",
   "metadata": {},
   "source": [
    "## Featurizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selective-citizenship",
   "metadata": {},
   "source": [
    "#### Descriptor: Morgan FP with radius 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "agreed-offset",
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = dc.feat.CircularFingerprint()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "complex-still",
   "metadata": {},
   "outputs": [],
   "source": [
    "pchem_feat = featurizer(list(df_pubchem_assays_new.canonical_smiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eight-affair",
   "metadata": {},
   "outputs": [],
   "source": [
    "pchem_labels = np.array(df_pubchem_assays_new[[s for s in df_pubchem_assays_new.columns if 'label' in s]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "spiritual-restriction",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcdf_pubchem = dc.data.NumpyDataset(X=pchem_feat, y=pchem_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specialized-faith",
   "metadata": {},
   "source": [
    "### Seeding and Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "processed-diagnosis",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_random_seeds_paper = [16, 102, 279, 314, 325, 376, 382, 398, 453, 490 , \n",
    "                           10, 133, 181, 202, 269, 304, 317, 392, 429, 447,\n",
    "                           109, 124, 137, 145, 155, 170, 297, 435, 470, 481,\n",
    "                           33, 37, 59, 76, 299, 340, 412, 444, 471, 493,\n",
    "                           48, 82, 132, 175, 191, 253, 264, 364, 399, 478]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "celtic-asbestos",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "regular-intermediate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "np.random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cooked-flash",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = dc.splits.RandomStratifiedSplitter()\n",
    "train_dataset, test_dataset = splitter.train_test_split(dcdf_pubchem, frac_train=0.8, seed = random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personal-boards",
   "metadata": {},
   "source": [
    "## Train Multitask Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "latin-perspective",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01821889281272888"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model \n",
    "n_features = dcdf_pubchem.X.shape[1]\n",
    "n_tasks = dcdf_pubchem.y.shape[1]\n",
    "model = dc.models.MultitaskClassifier(n_tasks, n_features)\n",
    "model.fit(train_dataset, nb_epoch=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "senior-massachusetts",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict test set\n",
    "y_true = test_dataset.y\n",
    "y_pred = model.predict(test_dataset)\n",
    "\n",
    "# predict training set\n",
    "train_y_true = train_dataset.y\n",
    "train_y_pred = model.predict(train_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unsigned-dryer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "auc = []\n",
    "kappa_th05 = []\n",
    "confusion_th05 = []\n",
    "metric = dc.metrics.roc_auc_score\n",
    "for i in range(n_tasks):\n",
    "    ### AUC\n",
    "    try:\n",
    "        auc_score = metric(dc.metrics.to_one_hot(y_true[:,i]), y_pred[:,i])\n",
    "        auc.append(auc_score)\n",
    "    except:\n",
    "        auc.append(np.nan)\n",
    "    test_probs = y_pred[:,i][:,1]\n",
    "    scores = [1 if x>=0.5 else 0 for x in test_probs]\n",
    "    ### Cohen's kappa\n",
    "    kappa = dc.metrics.cohen_kappa_score(y_true[:,i], scores)\n",
    "    kappa_th05.append(kappa)\n",
    "    ### Confusion Matrix\n",
    "    tn, fp, fn, tp = metrics.confusion_matrix(y_true[:,i], scores, labels=[0,1]).ravel()\n",
    "    confusion_th05.append([tn, fp, fn, tp])\n",
    "\n",
    "# optimize the decision threshold for each dataset and re-evaluate the model\n",
    "thresholds = np.round(np.arange(0.05,1.00,0.05),2)\n",
    "\n",
    "kappa_thopt = []\n",
    "opt_thresholds = []\n",
    "confusion_thopt = []\n",
    "for i in range(n_tasks):\n",
    "    test_probs = y_pred[:,i][:,1]\n",
    "    train_probs = train_y_pred[:,i][:,1]\n",
    "    # optimize threshold\n",
    "    opt_thresh = optimize_threshold_from_predictions(train_y_true[:,i], train_probs, thresholds, random_seed = random_seed)\n",
    "    opt_thresholds.append(opt_thresh)\n",
    "    # calculate Cohen's kappa with the optimized threshold\n",
    "    scores = [1 if x>=opt_thresh else 0 for x in test_probs]\n",
    "    kappa = dc.metrics.cohen_kappa_score(y_true[:,i], scores)\n",
    "    kappa_thopt.append(kappa)\n",
    "    ### Confusion Matrix\n",
    "    tn, fp, fn, tp = metrics.confusion_matrix(y_true[:,i], scores, labels=[0,1]).ravel()\n",
    "    confusion_thopt.append([tn, fp, fn, tp])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "subjective-alloy",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output = pd.DataFrame({'dataset':list(pubchem_assay_lookup.keys()), 'AUC':auc, 'kappa_Th05':kappa_th05, 'kappa_ThOpt':kappa_thopt, 'confusion_Th05':confusion_th05, 'confusion_ThOpt':confusion_thopt, 'ThOpt': opt_thresholds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "federal-bullet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>AUC</th>\n",
       "      <th>kappa_Th05</th>\n",
       "      <th>kappa_ThOpt</th>\n",
       "      <th>confusion_Th05</th>\n",
       "      <th>confusion_ThOpt</th>\n",
       "      <th>ThOpt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHEMBL1794375</td>\n",
       "      <td>0.705273</td>\n",
       "      <td>0.092442</td>\n",
       "      <td>0.118406</td>\n",
       "      <td>[32246, 149, 842, 56]</td>\n",
       "      <td>[32019, 376, 806, 92]</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHEMBL1614421</td>\n",
       "      <td>0.893486</td>\n",
       "      <td>0.414908</td>\n",
       "      <td>0.436691</td>\n",
       "      <td>[31828, 342, 721, 402]</td>\n",
       "      <td>[31725, 445, 663, 460]</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHEMBL1614249</td>\n",
       "      <td>0.712300</td>\n",
       "      <td>0.034083</td>\n",
       "      <td>0.058075</td>\n",
       "      <td>[33236, 7, 49, 1]</td>\n",
       "      <td>[33227, 16, 48, 2]</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHEMBL1614166</td>\n",
       "      <td>0.681152</td>\n",
       "      <td>0.166500</td>\n",
       "      <td>0.370174</td>\n",
       "      <td>[33271, 2, 18, 2]</td>\n",
       "      <td>[33271, 2, 15, 5]</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHEMBL1614364</td>\n",
       "      <td>0.757982</td>\n",
       "      <td>0.142237</td>\n",
       "      <td>0.140335</td>\n",
       "      <td>[33050, 58, 166, 19]</td>\n",
       "      <td>[33022, 86, 164, 21]</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CHEMBL1613933</td>\n",
       "      <td>0.999970</td>\n",
       "      <td>-0.000030</td>\n",
       "      <td>0.666653</td>\n",
       "      <td>[33291, 1, 1, 0]</td>\n",
       "      <td>[33291, 1, 0, 1]</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CHEMBL3214913</td>\n",
       "      <td>0.892981</td>\n",
       "      <td>0.274761</td>\n",
       "      <td>0.305905</td>\n",
       "      <td>[33051, 62, 141, 39]</td>\n",
       "      <td>[33025, 88, 131, 49]</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CHEMBL3215169</td>\n",
       "      <td>0.827974</td>\n",
       "      <td>0.213712</td>\n",
       "      <td>0.259146</td>\n",
       "      <td>[33152, 26, 98, 17]</td>\n",
       "      <td>[33120, 58, 89, 26]</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         dataset       AUC  kappa_Th05  kappa_ThOpt          confusion_Th05  \\\n",
       "0  CHEMBL1794375  0.705273    0.092442     0.118406   [32246, 149, 842, 56]   \n",
       "1  CHEMBL1614421  0.893486    0.414908     0.436691  [31828, 342, 721, 402]   \n",
       "2  CHEMBL1614249  0.712300    0.034083     0.058075       [33236, 7, 49, 1]   \n",
       "3  CHEMBL1614166  0.681152    0.166500     0.370174       [33271, 2, 18, 2]   \n",
       "4  CHEMBL1614364  0.757982    0.142237     0.140335    [33050, 58, 166, 19]   \n",
       "5  CHEMBL1613933  0.999970   -0.000030     0.666653        [33291, 1, 1, 0]   \n",
       "6  CHEMBL3214913  0.892981    0.274761     0.305905    [33051, 62, 141, 39]   \n",
       "7  CHEMBL3215169  0.827974    0.213712     0.259146     [33152, 26, 98, 17]   \n",
       "\n",
       "          confusion_ThOpt  ThOpt  \n",
       "0   [32019, 376, 806, 92]   0.25  \n",
       "1  [31725, 445, 663, 460]   0.40  \n",
       "2      [33227, 16, 48, 2]   0.20  \n",
       "3       [33271, 2, 15, 5]   0.10  \n",
       "4    [33022, 86, 164, 21]   0.30  \n",
       "5        [33291, 1, 0, 1]   0.05  \n",
       "6    [33025, 88, 131, 49]   0.30  \n",
       "7     [33120, 58, 89, 26]   0.15  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "commercial-replacement",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deepchem-test] *",
   "language": "python",
   "name": "conda-env-deepchem-test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
